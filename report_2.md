# GSM8K 监督微调阶段性实验报告

## 1. 背景与目标

* **目标**：在 GSM8K 上完成一套可复现的监督微调（SFT）与确定性评估流程，观察不同训练规模下的表现差异，分析异常波动的原因，并提出可操作的改进方案。
* **核心要求**：

  1. 训练阶段稳定、损失可解释；
  2. 评估阶段输出格式与判分严格对齐；
  3. 不同数据规模具有可比性与可复现性。

---

## 2. 方法概述（流程级）

* **训练数据与标注**：以题目为提示（prompt），以“思考 + 最终答案”结构为目标输出（`<think>…</think> <answer> … </answer>`）。
* **损失掩码**：仅对**响应 token**计损失，忽略 prompt 与 padding（`ignore_index=-100`），确保损失不被填充位扭曲。
* **训练设置**：单卡训练，AdamW 优化，梯度累积与梯度裁剪；同一学习率（2e-5），小规模多 epoch，大规模 1 epoch。
* **评估协议**：固定贪心解码（temperature=0），使用停词 `</answer>` 截止，以解析后的**最终数值答案**计分，避免采样噪声引入的方差。

> 注：评估在独立环境执行（vLLM），训练与评估解耦，避免彼此抢占显存/上下文。

---

## 3. 实验设计

* **数据规模**：`128 / 256 / 512 / 1024 / 全量(7473)`
* **Epochs**：`128, 256 → 3`；`512, 1024, 全量 → 1`
* **学习率**：`2e-5`（固定）
* **解码**：贪心、`max_new_tokens=1024`、`stop=["</answer>"]`

---

## 4. 实验结果（验证集贪心准确率）

| 训练规模 | Epochs |  学习率 |        准确率 |
| ---: | -----: | ---: | ---------: |
|  128 |      3 | 2e-5 | **55.50%** |
|  256 |      3 | 2e-5 |     49.13% |
|  512 |      1 | 2e-5 |     50.64% |
| 1024 |      1 | 2e-5 |     32.90% |
| 7473 |      1 | 2e-5 |  **4.17%** |

**现象概括**：

* 小样本（128）表现最佳（55.50%）；256 与 512 相近（≈50%）。
* 扩大到 1024 后准确率**显著下滑**；全量时出现**断崖式下降**（4.17%）。

---

## 5. 结果解读与初步判断

1. **“规模提升→性能提升”的常识未出现**

   * 512 与 256 无明显优势；1024 与全量反而下降，说明现阶段**不是典型欠拟合问题**。
2. **更像“评估对接/格式约束”导致的系统性失分**

   * 大样本训练后，模型更倾向于**长思考、晚给答案**，若 `</answer>` 未及时出现或答案格式与判分器略有偏差，将**整条样本被判 0 分**。
   * 小样本时模型对模板的“模仿”更强，反而更容易过评估。
3. **学习率相关，但非主因**

   * 固定 LR=2e-5 且无 warmup/schedule，可能在大样本下**放大风格漂移**（更话痨、更晚闭合）。
   * 但这不足以解释“从 50% 到 4% 的断崖”，主因仍指向**输出格式与判分协议错配**。

---

## 6. 可能成因（按优先级）

1. **评估对接问题（最关键）**

   * 未稳定触发 `<answer>…</answer>`；`</answer>` 未在 token 上限内出现；或最终数字被其它符号/文本夹杂，导致**解析失败**。
2. **训练目标设计**

   * 对 `<think>` 全段也进行了监督，模型强化了“长思考”风格，**弱化了“快速、规范地给出 final answer”** 的偏好。
3. **优化与调度不自适应**

   * 固定 LR+无 warmup/cosine，可能导致大规模早期“训偏了”，1 个 epoch 内来不及回收格式。
4. **数据异质性**

   * 随规模增大，长难样本与多样风格增多；若评估口径严格、容错低，容易出现**系统性低估**。

---

## 7. 诊断信号（建议立即统计）

* **未闭合率**：评估时统计“未出现 `</answer>`”的占比。
* **不可解析率**：能闭合但无法解析到**唯一数字**的占比。
* **监督 token 占比**：训练批次中 `(labels!=-100)` 的比例（监控掩码是否正确生效）。
* **答复长度分布**：`<think>` 长度、`<answer>` 出现位置、最终生成长度，观察是否普遍偏长/迟。

---

## 8. 改进方案（优先顺序与预期效果）

### 8.1 格式与评估对齐（最优先）

* **仅监督 `<answer>` 段**：将 `<think>` 全部设为忽略（不计损失），把学习重心放在**规范、可靠地产出 `<answer>`** 上。

  * **预期**：1024 与全量准确率显著回升，恢复随规模受益的趋势。
* **提示与模板强化**：在提示中明确要求**最后必须输出 `<answer> 数字 </answer>`**；可加入“禁止多答案/多个数”的指令。
* **解码健壮性**：保持 `stop=["</answer>"]`，适度增大 `max_new_tokens`，避免“思考过长导致来不及闭合”。

### 8.2 优化与调度

* **学习率搜索**：在 `5e-6, 1e-5, 2e-5, 3e-5` 做小范围 sweep。
* **调度**：`warmup 5% steps + cosine 衰减到 10–20% 基准 LR`，缓解早期风格漂移。
* **预算等效**：让不同规模的**总更新步数或总 token**尽量可比，排除预算差异干扰。

### 8.3 评估鲁棒性（诊断用）

* **双口径指标**：

  * **严格指标**（当前口径，保留可对比）；
  * **诊断指标**（若无 `</answer>`，则取**最后一个数字**进行对比），用于识别“会做题但格式失败”。

---

## 9. 两周复现实验计划（可直接执行）

**对象**：`512 / 1024 / 全量` 三档
**矩阵**：

1. **A 组（基线+)**：现有流程 + `warmup+cosine`（不改训练目标）。
2. **B 组（关键改动）**：A 组 + **仅监督 `<answer>`**。
3. **C 组（稳健化）**：B 组 + **LR 下调一档**（如 1e-5）。

**记录**：严格准确率、诊断准确率、未闭合率、不可解析率、答复长度分布。
**成功准则**：

* 1024 与全量在 **B/C 组**准确率**显著高于** A 组；
* 未闭合率与不可解析率**明显下降**；
* 小样本（128/256）不劣于现有结果。

---

## 10. 风险与注意事项

* **口径漂移**：评估口径如有变动，务必保留“严格指标”，确保横向对比公平。
* **可复现性**：固定随机种子、环境版本；保存评估日志以便回溯。
* **显存与资源**：评估显存占用可按需降低，保证一次只存在一个评估引擎。

---

## 11. 结论

* 目前结果显示：**规模扩大后并未提升，且在全量出现极端下滑**。主因更可能是**输出格式与判分对接不稳**而非模型能力退化。
* 按优先级采取“**仅监督 `<answer>`** + **提示/停词/长度约束** + **warmup+cosine** + **小范围 LR 搜索**”，预计中大规模（≥1024）将**明显回升**，并恢复“规模受益”的合理走势。

---

## 12. 附录：执行要点（简版）

* **训练**：仅对 `<answer>` 计损失；`AdamW`，`clip_grad_norm=1.0`；加入 `warmup 5% + cosine`；LR 试 `{5e-6, 1e-5, 2e-5, 3e-5}`。
* **评估**：贪心、`max_new_tokens` 视目标长度上调、`stop=["</answer>"]`；统计未闭合/不可解析比例；保留严格与诊断两条指标。
* **对比**：在 `512/1024/全量` 三档做 A/B/C 组实验，观察准确率与诊断指标的协同改善。
