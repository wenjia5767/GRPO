{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b56f5209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a script to evaluate Qwen 2.5 Math 1.5B zero-shot performance on gsm8k\n",
    "# Load the gsm8k examples from file.\n",
    "from datasets import load_dataset\n",
    "import re\n",
    "\n",
    "main_ds = load_dataset(\n",
    "    \"parquet\",\n",
    "    data_files = {\n",
    "        \"train\": \"/home/zhangwj/gsm8k/main/train-00000-of-00001.parquet\",\n",
    "        \"test\": \"/home/zhangwj/gsm8k/main/test-00000-of-00001.parquet\",\n",
    "    }\n",
    ")\n",
    "\n",
    "socratic_ds = load_dataset(\n",
    "    \"parquet\",\n",
    "    data_files={\n",
    "        \"train\": \"/home/zhangwj/gsm8k/socratic/train-00000-of-00001.parquet\",\n",
    "        \"test\": \"/home/zhangwj/gsm8k/socratic/test-00000-of-00001.parquet\",\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bf194b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1,  2,  3,  4,  5],\n",
      "        [ 6,  7,  8,  9, 10]])\n",
      "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "y = torch.tensor([1,2,3,4,5,6,7,8,9,10])\n",
    "x = y.reshape(2, 5)\n",
    "print(x)\n",
    "z = x.reshape(10,)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53b1bbf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1, 10,  3, 12])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Create two tensors\n",
    "x = torch.tensor([1, 15, 3, 20])\n",
    "y = torch.tensor([5, 10, 8, 12])\n",
    "\n",
    "# Find the element-wise minimum\n",
    "z = torch.min(x, y)\n",
    "\n",
    "print(z)\n",
    "# Output: tensor([1, 10, 3, 12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41097f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?', 'answer': 'Natalia sold 48/2 = <<48/2=24>>24 clips in May.\\nNatalia sold 48+24 = <<48+24=72>>72 clips altogether in April and May.\\n#### 72'}\n"
     ]
    }
   ],
   "source": [
    "print(main_ds['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3351d6f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': \"Every day, Wendi feeds each of her chickens three cups of mixed chicken feed, containing seeds, mealworms and vegetables to help keep them healthy.  She gives the chickens their feed in three separate meals. In the morning, she gives her flock of chickens 15 cups of feed.  In the afternoon, she gives her chickens another 25 cups of feed.  How many cups of feed does she need to give her chickens in the final meal of the day if the size of Wendi's flock is 20 chickens?\", 'answer': 'If each chicken eats 3 cups of feed per day, then for 20 chickens they would need 3*20=<<3*20=60>>60 cups of feed per day.\\nIf she feeds the flock 15 cups of feed in the morning, and 25 cups in the afternoon, then the final meal would require 60-15-25=<<60-15-25=20>>20 cups of chicken feed.\\n#### 20'}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "file_path = \"/home/zhangwj/assignment5/data/gsm8k/test.jsonl\"\n",
    "dataset = load_dataset('json', data_files=file_path)\n",
    "print(dataset[\"train\"][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06bc86c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "print([1, 2] + [3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "634f3f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1319/1319 [00:00<00:00, 36287.05 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A conversation between User and Assistant. The User asks a question, and the Assistant solves it. The Assistant first thinks about the reasoning process in the mind and then provides the User with the answer. The reasoning process is enclosed within <think> </think> and answer is enclosed within <answer> </answer> tags, respectively, i.e., <think> reasoning process here </think> <answer> answer here </answer>.\n",
      "\n",
      "User: Janet’s ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market?\n",
      "Assistant: <think> Janet sells 16 - 3 - 4 = <<16-3-4=9>>9 duck eggs a day.\n",
      "She makes 9 * 2 = $<<9*2=18>>18 every day at the farmer’s market. </think> <answer> 18 </answer>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "main_ds = main_ds[\"test\"]\n",
    "\n",
    "def format_r1_zero(example):\n",
    "    # Separate reasoning from final answe\n",
    "    answer_text = example[\"answer\"].strip()\n",
    "    match = re.search(r\"####\\s*(.*)\", answer_text)\n",
    "    if match:\n",
    "        final_answer = match.group(1).strip()\n",
    "        reasoning = answer_text[:match.start()].strip()\n",
    "    else:\n",
    "        reasoning = answer_text\n",
    "        final_answer = \"\"\n",
    "    \n",
    "    # Build the r1_zero_style prompt\n",
    "    prompt = (\n",
    "        \"A conversation between User and Assistant. The User asks a question, \"\n",
    "        \"and the Assistant solves it. The Assistant first thinks about the reasoning \"\n",
    "        \"process in the mind and then provides the User with the answer. \"\n",
    "        \"The reasoning process is enclosed within <think> </think> and answer is enclosed \"\n",
    "        \"within <answer> </answer> tags, respectively, \"\n",
    "        \"i.e., <think> reasoning process here </think> <answer> answer here </answer>.\\n\\n\"\n",
    "        f\"User: {example['question']}\\n\"\n",
    "        f\"Assistant: <think> {reasoning} </think> <answer> {final_answer} </answer>\"\n",
    "    )\n",
    "    return {\"prompt\": prompt}\n",
    "\n",
    "# Apply to the dataset\n",
    "formatted_ds = main_ds.map(format_r1_zero)\n",
    "\n",
    "print(formatted_ds[0][\"prompt\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d082cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'alignment (Python 3.12.4)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/home/zhangwj/assignment5/.venv/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from vllm import LLM, SamplingParams\n",
    "\n",
    "def main():\n",
    "    # Sample prompts.\n",
    "    prompts = [\n",
    "        \"Hello, my name is\",\n",
    "        \"The president of the United States is\",\n",
    "        \"The capital of France is\",\n",
    "        \"The future of AI is\",\n",
    "    ]\n",
    "\n",
    "    # Create a sampling params object, stopping generation on new line.\n",
    "    sampling_params = SamplingParams(\n",
    "        temperature=1.0, top_p=1.0, max_tokens=1024, stop=[\"\\n\"]\n",
    "    )\n",
    "\n",
    "    # Create an LLM\n",
    "    llm = LLM(model=\"/home/zhangwj/Qwen2.5-3B-Instruct\")\n",
    "    # llm = LLM(model=\"./Qwen2.5-Math-1.5B\")\n",
    "\n",
    "    # Generate texts from the prompts. The output is a list of RequestOutput objects\n",
    "    # that contain the prompt, generated text, and other information.\n",
    "\n",
    "    outputs = llm.generate(prompts, sampling_params)\n",
    "\n",
    "\n",
    "    # Print the outputs.\n",
    "    for output in outputs:\n",
    "        prompt = output.prompt\n",
    "        generated_text = output.outputs[0].text\n",
    "        print(f\"Prompt: {prompt!r}, Generated text: {generated_text!r}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alignment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
